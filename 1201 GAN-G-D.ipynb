{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목표\n",
    "\n",
    "Conv based로 D 모델만 학습이 가능한지 확인.\n",
    "\n",
    "1. 가상의 G 모델(CLSTMC, pretrained)로 testset에 대해 prediction들을 생성\n",
    "2. 생성한 데이터를 npy 파일로 저장\n",
    "3. D 모델에서 가짜와 진짜 데이터를 구분이 가능한지(예측 데이터와 실제 데이터에 실제로 차이가 있는지) 를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path\n",
    "from typing import List, Union, AnyStr\n",
    "from math import pi\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from sklearn import model_selection\n",
    "from tqdm import tqdm\n",
    "import torch_optimizer\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import random\n",
    "from torchvision.models.resnet import resnet18\n",
    "\n",
    "import torch_burn as tb\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = '1201-GAN-G-D'\n",
    "CHECKPOINT_DIR = Path('checkpoint', EXPERIMENT_NAME)\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_DIR = Path('data/1116')\n",
    "TRAIN_FILES = sorted(list(DATA_DIR.glob('*scene3_0.csv')))\n",
    "TEST_FILES = sorted(list(DATA_DIR.glob('*scene3_1.csv')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_result(checkpoint_dir):\n",
    "    d = Path(checkpoint_dir)\n",
    "    X = np.load(d / 'result-X.npy')\n",
    "    Y = np.load(d / 'result-Y.npy')\n",
    "    P = np.load(d / 'result-P.npy')\n",
    "    return X, Y, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, P = load_result('checkpoint/1130-Scene3-CLSTMC4-X60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54167, 60, 6), (54167, 3), (54167, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectorDataset(Dataset):\n",
    "    def __init__(self, Y, P, L):\n",
    "        super(DetectorDataset, self).__init__()\n",
    "\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32).transpose(0, 1)\n",
    "        self.P = torch.tensor(P, dtype=torch.float32).transpose(0, 1)\n",
    "        self.L = L\n",
    "        self.Ysize = self.Y.shape[1] // self.L\n",
    "        self.Psize = self.P.shape[1] // self.L\n",
    "        self.dssize = self.Ysize + self.Psize\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dssize\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.Ysize:\n",
    "            input = self.Y[:, idx:idx + self.L]\n",
    "            target = torch.tensor([0], dtype=torch.float32)\n",
    "        else:\n",
    "            idx -= self.Ysize\n",
    "            input = self.P[:, idx:idx + self.L]\n",
    "            target = torch.tensor([1], dtype=torch.float32)\n",
    "        return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DetectorDataset(Y, P, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Common Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock1d(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, inchannels, channels, kernel_size, stride=1, groups=1):\n",
    "        super(ResBlock1d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(inchannels, channels, kernel_size, padding=kernel_size // 2, stride=stride, groups=groups),\n",
    "            nn.BatchNorm1d(channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(channels, channels, kernel_size, padding=kernel_size // 2, groups=groups),\n",
    "            nn.BatchNorm1d(channels)\n",
    "        )\n",
    "        self.act = nn.LeakyReLU()\n",
    "        \n",
    "        self.conv2 = None\n",
    "        if inchannels != channels:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.Conv1d(inchannels, channels, 1, stride=stride, groups=groups),\n",
    "                nn.BatchNorm1d(channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        if self.conv2 is not None:\n",
    "            identity = self.conv2(identity)\n",
    "        x += identity\n",
    "        x = self.act(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D Model - Resnet15 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDetector(nn.Module):\n",
    "    def __init__(self, block, layers):\n",
    "        super(ConvDetector, self).__init__()\n",
    "        \n",
    "        self.inchannels = 64\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(3, self.inchannels, 7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _make_layer(self, block, channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.inchannels, channels, 3))\n",
    "        self.inchannels = channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inchannels, channels, 3))\n",
    "        \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G Model - Conv Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GModel, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(64, 3, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = ConvDetector(ResBlock1d, [2, 2, 2, 2]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = GModel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 60]), torch.Size([1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = ds[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 60])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G(x.unsqueeze(0).cuda()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = int(len(ds) * 0.2)\n",
    "ds_train, ds_test = random_split(ds, [len(ds) - valid_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=256, num_workers=8, pin_memory=True, shuffle=True)\n",
    "dl_test  = DataLoader(ds_test,  batch_size=256, num_workers=8, pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 101):\n",
    "    # Training D\n",
    "    with tqdm(total=len(dl_train), position=0, ncols=100) as t:\n",
    "        for x, y in dl_train:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            p = G(x)\n",
    "            \n",
    "            loss_D = D(y)\n",
    "            z\n",
    "            \n",
    "        \n",
    "    # Training G\n",
    "    with tqdm(total=len(dl_train), position=0, ncols=100) as t:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
