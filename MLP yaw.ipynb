{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from xqdm import xqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import keras.layers as L\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shim/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "I = L.Input(shape=(6,))\n",
    "x = L.Dense(12, activation='tanh')(I)\n",
    "x = L.Dense(24, activation='tanh')(x)\n",
    "x = L.Dropout(0.2)(x)\n",
    "x = L.Dense(48, activation='tanh')(x)\n",
    "x = L.Dropout(0.2)(x)\n",
    "x = L.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = Model(inputs=I, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                1200      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 49        \n",
      "=================================================================\n",
      "Total params: 1,645\n",
      "Trainable params: 1,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178927, 6) (178544, 6) (178927,) (178544,)\n"
     ]
    }
   ],
   "source": [
    "with open('data/mlp300_yaw.pkl', 'rb') as f:\n",
    "    X_train, X_test, Y_train, Y_test = pickle.load(f)\n",
    "\n",
    "#X = np.stack(X, axis=0)\n",
    "#Y = np.stack(Y, axis=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '0008'\n",
    "checkpoint_dir = Path('checkpoint') / name\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = str(checkpoint_dir / ('ckpt-%s-epoch{epoch:04d}-val_loss{val_loss:.4f}.hdf5'%name))\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(verbose=1),\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ModelCheckpoint(checkpoint_path, verbose=1, save_best_only=True),\n",
    "    TensorBoard(log_dir=checkpoint_dir)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shim/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 178927 samples, validate on 178544 samples\n",
      "WARNING:tensorflow:From /home/shim/anaconda3/envs/tf/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/shim/anaconda3/envs/tf/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0118 - val_loss: 0.0028\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00285, saving model to checkpoint/0008/ckpt-0008-epoch0001-val_loss0.0028.hdf5\n",
      "WARNING:tensorflow:From /home/shim/anaconda3/envs/tf/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0077 - val_loss: 0.0031\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00285\n",
      "Epoch 3/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0073 - val_loss: 0.0027\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00285 to 0.00269, saving model to checkpoint/0008/ckpt-0008-epoch0003-val_loss0.0027.hdf5\n",
      "Epoch 4/100\n",
      "178927/178927 [==============================] - 2s 12us/step - loss: 0.0071 - val_loss: 0.0028\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00269\n",
      "Epoch 5/100\n",
      "178927/178927 [==============================] - 2s 12us/step - loss: 0.0068 - val_loss: 0.0028\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00269\n",
      "Epoch 6/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0069 - val_loss: 0.0028\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00269\n",
      "Epoch 7/100\n",
      "178927/178927 [==============================] - 2s 12us/step - loss: 0.0068 - val_loss: 0.0028\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00269\n",
      "Epoch 8/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0068 - val_loss: 0.0025\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00269 to 0.00248, saving model to checkpoint/0008/ckpt-0008-epoch0008-val_loss0.0025.hdf5\n",
      "Epoch 9/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0068 - val_loss: 0.0025\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00248\n",
      "Epoch 10/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0066 - val_loss: 0.0027\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00248\n",
      "Epoch 11/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0066 - val_loss: 0.0026\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00248\n",
      "Epoch 12/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0068 - val_loss: 0.0026\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00248\n",
      "Epoch 13/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00248\n",
      "Epoch 14/100\n",
      "178927/178927 [==============================] - 2s 12us/step - loss: 0.0066 - val_loss: 0.0025\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00248\n",
      "Epoch 15/100\n",
      "178927/178927 [==============================] - 2s 12us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00248\n",
      "Epoch 16/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00248\n",
      "Epoch 17/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00248\n",
      "Epoch 18/100\n",
      "178927/178927 [==============================] - 2s 13us/step - loss: 0.0068 - val_loss: 0.0025\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00248\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9d30e1f550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=64, epochs=100, validation_data=(X_test, Y_test), verbose=1, shuffle=False, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
